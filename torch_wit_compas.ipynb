{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-f0819b38-c012-4fd9-b1a0-40b32986cb21",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 318.171875,
    "deepnote_cell_type": "code",
    "id": "wzEwkr3SoyLh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%load_ext autoreload\n",
    "%matplotlib widget\n",
    "\n",
    "import sys, os, pickle, pdb, shutil, re, math\n",
    "from copy import deepcopy, copy\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd, numpy as np, torch\n",
    "from sklearn.utils import shuffle\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import lime_fit, sample_around\n",
    "\n",
    "paths = [Path(\"\").parent.absolute() / \"shap\", Path(\"\").parent.absolute() / \"shap_original\"]\n",
    "for path in paths:\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.insert(0, str(path))\n",
    "import shap, shap_original\n",
    "\n",
    "DTYPE, DEVICE = torch.float32, torch.device(\"cuda\")\n",
    "TOPTS = dict(dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00002-f0819b38-c012-4fd9-b1a0-40b32986cb21",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 318.171875,
    "deepnote_cell_type": "code",
    "id": "wzEwkr3SoyLh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(\"\") / \"data\" / \"compas\" / \"cox-violent-parsed_filt.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df[\"is_recid\"] != -1]\n",
    "df = df[df[\"decile_score\"] != -1]\n",
    "\n",
    "# Rename recidivism column\n",
    "df[\"recidivism_within_2_years\"] = df[\"is_recid\"]\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df[\"COMPASS_determination\"] = np.where(df[\"score_text\"] == \"Low\", 0, 1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"sex\", \"race\"])\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "input_features = [\n",
    "    \"sex_Female\",\n",
    "    \"sex_Male\",\n",
    "    \"age\",\n",
    "    \"race_African-American\",\n",
    "    \"race_Caucasian\",\n",
    "    \"race_Hispanic\",\n",
    "    \"race_Native American\",\n",
    "    \"race_Other\",\n",
    "    \"priors_count\",\n",
    "    \"juv_fel_count\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "]\n",
    "\n",
    "to_keep = input_features + [\"recidivism_within_2_years\", \"COMPASS_determination\"]\n",
    "\n",
    "to_remove = [col for col in df.columns if col not in to_keep]\n",
    "df = df.drop(columns=to_remove)\n",
    "\n",
    "input_columns = df.columns.tolist()\n",
    "labels = df[\"COMPASS_determination\"]\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00004-de54ccf0-cc72-441f-9628-7a908132a348",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 246.15625,
    "deepnote_cell_type": "code",
    "id": "U0ZfePT1rTmZ"
   },
   "outputs": [],
   "source": [
    "# Create data structures needing for training and testing.\n",
    "# The training data doesn't contain the column we are predicting,\n",
    "# 'COMPASS_determination', or the column we are using for evaluation of our\n",
    "# trained model, 'recidivism_within_2_years'.\n",
    "df_for_training = df.drop(columns=[\"COMPASS_determination\", \"recidivism_within_2_years\"])\n",
    "train_size = int(len(df_for_training) * 0.8)\n",
    "\n",
    "train_data = df_for_training[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "test_data = df_for_training[train_size:]\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "test_data_with_labels = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = train_data.values, train_labels.values\n",
    "Xts, Yts = test_data.values, test_labels.values\n",
    "MU, STD = np.mean(Xtr, -2), np.std(Xtr, -2)\n",
    "normalize_fn = lambda x: (x - MU[None, ...]) / STD[None, ...]\n",
    "Xtr = normalize_fn(Xtr)\n",
    "Xts = normalize_fn(Xts)\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(*[Xtr, Ytr])), batch_size=1024, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(list(zip(*[Xts, Yts])), batch_size=1024, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00005-62743ad9-fb8b-453d-9b8e-f601cd11e0da",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 264.15625,
    "deepnote_cell_type": "code",
    "id": "5T2XThgosWX-"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "# This is the size of the array we'll be feeding into our model for each example\n",
    "input_size = len(train_data.iloc[0])\n",
    "\n",
    "RACE_IDX = [i for (i, z) in enumerate(train_data.columns) if re.match(r\"race_.*\", z) is not None]\n",
    "\n",
    "# activation = torch.nn.ReLU()\n",
    "activation = torch.nn.Softplus(1e2)\n",
    "\n",
    "\n",
    "def generate_model():\n",
    "    model = (\n",
    "        torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 128),\n",
    "            copy(activation),\n",
    "            torch.nn.Linear(128, 128),\n",
    "            copy(activation),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        .to(DTYPE)\n",
    "        .to(DEVICE)\n",
    "    )\n",
    "    loss_obj = torch.nn.BCELoss()\n",
    "    lam = 1e-3\n",
    "    loss_fn = lambda Yp, Y: loss_obj(Yp, Y) + sum(lam * torch.sum(param**2) / 2 for param in model.parameters())\n",
    "\n",
    "    x0 = torch.as_tensor(Xtr[torch.randint(0, Xtr.shape[0], size=(1000,)), :], device=DEVICE, dtype=DTYPE)\n",
    "    Xs = sample_around(x0, torch.tensor(STD, device=DEVICE, dtype=DTYPE), N=int(1e2), alf=1e-2)\n",
    "    Xs = Xs.transpose(0, 1)\n",
    "    loss_fn_ = loss_fn\n",
    "\n",
    "    def loss_fn(Yp, Y, penalize=True, penalty=\"exact\", gam=1e1):\n",
    "        ret = loss_fn_(Yp, Y)\n",
    "        if penalize:\n",
    "            Yp = model(Xs)\n",
    "            W, b = lime_fit(Xs, Yp)\n",
    "            if penalty == \"exact\":\n",
    "                ret = ret + gam * torch.mean(torch.norm(W[..., RACE_IDX, 0], dim=-1))\n",
    "            elif penalty == \"mse\":\n",
    "                ret = ret + gam * torch.mean(torch.norm(W[..., RACE_IDX, 0], dim=-1) ** 2)\n",
    "            elif penalty == \"super-exact\":\n",
    "                ret = ret + gam * torch.mean(torch.sqrt(torch.norm(W[..., RACE_IDX, 0], dim=-1)))\n",
    "            else:\n",
    "                raise ValueError(f\"penalty [{penalty}] is not supported\")\n",
    "        return ret\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.3)\n",
    "    return model, loss_fn, optimizer, scheduler, Xs\n",
    "\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    correct = 0\n",
    "    for X, Y in loader:\n",
    "        X, Y = X.to(DTYPE).to(DEVICE), Y.to(DEVICE)\n",
    "        Yp = model(X)\n",
    "        correct += torch.sum((Yp > 0.5).reshape(Y.shape) == Y).detach()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88199debf6a64ecfbbc57bca239733cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = False\n",
      "0.3325492739677429\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d529af8fe947c0be6bb941a29a05c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = exact\n",
      "0.00370749831199646\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9946e8ef2884f488dd7a45cfdfd5e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = mse\n",
      "0.009267126210033894\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80cdcbc9eef4065b2731214e8e68de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "0.0019427312072366476\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "accs, metrics = [], []\n",
    "for (penalize, penalty, gam) in [\n",
    "    (False, \"exact\", 1e1),\n",
    "    (True, \"exact\", 1e1),\n",
    "    (True, \"mse\", 1e2),\n",
    "    (True, \"super-exact\", 1.5e0),\n",
    "]:\n",
    "    model, loss_fn, optimizer, scheduler, Xs = generate_model()\n",
    "    shutil.rmtree(Path(\"\") / \"runs\")\n",
    "    writer = SummaryWriter()\n",
    "    rng = tqdm(range(int(10)))\n",
    "    for epoch in rng:\n",
    "        for (i, (X, Y)) in enumerate(train_loader):\n",
    "            X, Y = X.to(DTYPE).to(DEVICE), Y.to(DTYPE).to(DEVICE)\n",
    "            loss = loss_fn(model(X).reshape(Y.shape), Y, penalize=penalize, penalty=penalty, gam=gam)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # rng.set_description(f\"{loss.detach():.4e}\")\n",
    "            writer.add_scalar(\"loss/train\", float(loss), i + epoch * len(train_loader))\n",
    "            writer.add_scalar(\"step_size\", float(optimizer.param_groups[0][\"lr\"]), i + epoch * len(train_loader))\n",
    "            writer.flush()\n",
    "        scheduler.step()\n",
    "        # tqdm.write(f\"Accuracy = {1e2 * accuracy(model, test_loader):.3f}%\")\n",
    "        rng.set_description(\n",
    "            f\"Accuracy = (test = {1e2 * accuracy(model, test_loader):.3f}%,\"\n",
    "            + f\"train = {1e2 * accuracy(model, train_loader):.3f}%)\"\n",
    "        )\n",
    "        # tqdm.write(f\"Loss =     {loss_obj(model(X).reshape(Y.shape), Y):.5e}\")\n",
    "\n",
    "    W, b = lime_fit(Xs, model(Xs))\n",
    "    print(f\"Penalize = {penalize}\")\n",
    "    if penalize:\n",
    "        print(f\"Penalty = {penalty}\")\n",
    "    metric = torch.mean(torch.norm(W[..., RACE_IDX, 0], dim=-1))\n",
    "    print(float(metric))\n",
    "    accs.append(float(1e2 * accuracy(model, test_loader)))\n",
    "    metrics.append(float(metric))\n",
    "    print(\"#\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gam(gam):\n",
    "    model, loss_fn, optimizer, scheduler, Xs = generate_model()\n",
    "    shutil.rmtree(Path(\"\") / \"runs\")\n",
    "    writer = SummaryWriter()\n",
    "    rng = tqdm(range(int(10)))\n",
    "    for epoch in rng:\n",
    "        for (i, (X, Y)) in enumerate(train_loader):\n",
    "            X, Y = X.to(DTYPE).to(DEVICE), Y.to(DTYPE).to(DEVICE)\n",
    "            loss = loss_fn(model(X).reshape(Y.shape), Y, penalize=True, penalty=\"exact\", gam=gam)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"loss/train\", float(loss), i + epoch * len(train_loader))\n",
    "            writer.add_scalar(\"step_size\", float(optimizer.param_groups[0][\"lr\"]), i + epoch * len(train_loader))\n",
    "            writer.flush()\n",
    "        scheduler.step()\n",
    "        # tqdm.write(f\"Accuracy = {1e2 * accuracy(model, test_loader):.3f}%\")\n",
    "        rng.set_description(\n",
    "            f\"Accuracy = (test = {1e2 * accuracy(model, test_loader):.3f}%,\"\n",
    "            + f\"train = {1e2 * accuracy(model, train_loader):.3f}%)\"\n",
    "        )\n",
    "        # tqdm.write(f\"Loss =     {loss_obj(model(X).reshape(Y.shape), Y):.5e}\")\n",
    "\n",
    "    W, b = lime_fit(Xs, model(Xs))\n",
    "    print(f\"Penalize = {penalize}\")\n",
    "    if penalize:\n",
    "        print(f\"Penalty = {penalty}\")\n",
    "        print(f\"Gam = {gam}\")\n",
    "    metric = torch.mean(torch.norm(W[..., RACE_IDX, 0], dim=-1))\n",
    "    print(metric)\n",
    "    print(\"#\" * 80)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42e6a6a86644ce2b116f60012c7f81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 0.01\n",
      "tensor(0.2527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b532516a986c469881ead770d71267c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 0.027825594022071243\n",
      "tensor(0.1842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140d575fd68f463890312e5665e83648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 0.0774263682681127\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7c01bec43a48daabfc0a0eb0120a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 0.21544346900318834\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31690e1f5eb14a38a4e36daf00651e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 0.5994842503189409\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ba9ccca50e449a8ca4e273063f7e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 1.6681005372000592\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c09642911c493e93d11aea68d3566c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 4.6415888336127775\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b9c52f85204c87b9b001844c26d2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 12.915496650148826\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db88e34cd394d4b8f52d2d1ca681e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 35.93813663804626\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e338b6f498ce43738312c51230dd47f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalize = True\n",
      "Penalty = super-exact\n",
      "Gam = 100.0\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "gams = 10.0 ** np.linspace(-2, 2, 10)\n",
    "vals = [check_gam(gam) for gam in gams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing differentiating through Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00007-7ae41274-6190-4adc-9032-8271acd18d87",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 102.15625,
    "deepnote_cell_type": "code",
    "id": "lI18CwYiQotq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4286e-07, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a SHAP explainer by passing a subset of our training data\n",
    "model, loss_fn, optimizer, scheduler, Xs = generate_model()\n",
    "X = torch.as_tensor(train_data.values[:200], **TOPTS)\n",
    "\n",
    "explainer = shap.DeepExplainer(deepcopy(model), X)\n",
    "vals1 = explainer.shap_values(X[:10, :])\n",
    "\n",
    "explainer_original = shap_original.DeepExplainer(deepcopy(model), X)\n",
    "vals2 = torch.as_tensor(explainer_original.shap_values(X[:10, :]), **TOPTS)\n",
    "\n",
    "print(torch.norm(vals1 - vals2) / torch.norm(vals1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "00008-00ffe487-503b-4e02-85f5-d54c70e57ecb",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 120.171875,
    "deepnote_cell_type": "code",
    "id": "iywHwbJJkeYG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.71903102e-02, -1.97675225e-04, -1.98997383e-04,\n",
       "        -1.92532389e-04, -4.12244089e-02, -1.43817724e-09,\n",
       "         1.28570010e-09, -1.71174586e-04,  1.77759330e-06,\n",
       "         3.25610164e-11,  0.00000000e+00, -3.68765322e-04],\n",
       "       [-5.71903102e-02, -1.97675225e-04, -1.98997383e-04,\n",
       "        -1.92532389e-04, -4.12244089e-02, -1.43817724e-09,\n",
       "         1.28570010e-09, -1.71174586e-04,  1.77759330e-06,\n",
       "         3.25610164e-11,  0.00000000e+00, -3.68765322e-04],\n",
       "       [-6.04670588e-03, -3.85728083e-04, -3.56173958e-04,\n",
       "        -4.00341756e-04, -8.20497125e-02, -4.35711378e-09,\n",
       "         2.81565038e-09,  2.28080557e-06,  3.80985762e-06,\n",
       "         1.35330511e-10,  0.00000000e+00,  1.81077341e-11],\n",
       "       [ 5.16895279e-02, -7.97657587e-04, -5.81035041e-04,\n",
       "        -3.81269056e-04, -1.27719998e-01, -1.18468336e-07,\n",
       "        -3.39043034e-08,  8.59804459e-06,  1.11365889e-05,\n",
       "         9.25007129e-08,  0.00000000e+00,  1.37961976e-07],\n",
       "       [ 5.16895279e-02, -7.97657587e-04, -5.81035041e-04,\n",
       "        -3.81269056e-04, -1.27719998e-01, -1.18468336e-07,\n",
       "        -3.39043034e-08,  8.59804459e-06,  1.11365889e-05,\n",
       "         9.25007129e-08,  0.00000000e+00,  1.37961976e-07]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explain predictions of the model on the first 5 examples from our training set\n",
    "# to test the SHAP explainer.\n",
    "shap_values = explainer.shap_values(torch.tensor(train_data.values[:5]).to(DTYPE).to(DEVICE))\n",
    "shap_values\n",
    "# print(shap_values[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WIT COMPAS with SHAP",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "f3c3b30d-7a29-47a3-a6e6-89fe2e1d8b52",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
