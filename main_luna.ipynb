{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-f0819b38-c012-4fd9-b1a0-40b32986cb21",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 318.171875,
    "deepnote_cell_type": "code",
    "id": "wzEwkr3SoyLh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%autoreload 2\n",
    "%load_ext autoreload\n",
    "\n",
    "import sys, os, pickle, pdb, shutil, re, math, glob\n",
    "from copy import deepcopy, copy\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Union, Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import psutil\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd, numpy as np, torch, matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from ipywidgets import interact\n",
    "import skimage.io\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "from whack.penalty_functions import mse_penalty, exact_penalty, super_exact_penalty\n",
    "from whack.penalties import LIME_penalty, SHAP_penalty, LIME_focus\n",
    "\n",
    "# import the shap module\n",
    "paths = [Path(\"\").parent.absolute() / \"shap\", Path(\"\").parent.absolute() / \"shap_original\"]\n",
    "for path in paths:\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.insert(0, str(path))\n",
    "import shap, shap_original\n",
    "\n",
    "# set the global dtype and device to work with\n",
    "DTYPE, DEVICE = torch.float32, torch.device(\"cuda\")\n",
    "TOPTS = dict(dtype=DTYPE, device=DEVICE)  # tensor options\n",
    "plt.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = Path(\"/media/rdyro/Storage/datasets/LUNA16\").absolute() / \"mhd\"\n",
    "image_fnames = glob.glob(str(image_root / \"*.mhd\"))\n",
    "\n",
    "text_root = Path(\"\").absolute() / \"data\" / \"lung\"\n",
    "annotations_df = pd.read_csv(text_root / \"annotations.csv\")\n",
    "candidates_df = pd.read_csv(text_root / \"candidates_V2.csv\")\n",
    "data_df = candidates_df\n",
    "\n",
    "all_samples = np.unique(data_df[\"seriesuid\"])\n",
    "\n",
    "fname = Path(\"\").absolute() / \"data\" / \"candidates_dict.bin\"\n",
    "if fname.exists():\n",
    "    cand_map = torch.load(fname)\n",
    "else:\n",
    "    cand_map = dict()\n",
    "    for (i, row) in candidates_df.iterrows():\n",
    "        name = row[\"seriesuid\"]\n",
    "        cand_map.setdefault(name, [])\n",
    "        x, y, z, c = row[\"coordX\"], row[\"coordY\"], row[\"coordZ\"], row[\"class\"]\n",
    "        cand_map[name].append([x, y, z, c])\n",
    "    for k in cand_map.keys():\n",
    "        cand_map[k] = np.array(cand_map[k])\n",
    "    torch.save(cand_map, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz2pixels(image: sitk.SimpleITK.Image, x, y, z):\n",
    "    return image.TransformPhysicalPointToIndex((x, y, z))\n",
    "    # return tuple((np.array([x, y, z]) - np.array(image.GetOrigin())) / np.array(image.GetSpacing()))\n",
    "\n",
    "\n",
    "def pixels2xyz(image, px, py, pz):\n",
    "    return image.TransformIndexToPhysicalPoint((px, py, pz))\n",
    "    # return tuple(np.array([px, py, pz]) * np.array(image.GetSpacing()) + np.array(image.GetOrigin()))\n",
    "\n",
    "\n",
    "def get_class(name, x, y, z):\n",
    "    d = np.linalg.norm(cand_map[name][:, :3] - np.array([x, y, z]), axis=-1)\n",
    "    idx = np.argmin(d)\n",
    "    assert d[idx] <= 2\n",
    "    return cand_map[name][idx, -1]\n",
    "\n",
    "\n",
    "def crop_positive(name, size=30):\n",
    "    img_path = image_root / (name + \".mhd\")\n",
    "    reader = sitk.ImageFileReader()\n",
    "    reader.SetImageIO(\"MetaImageIO\")\n",
    "    reader.SetFileName(str(img_path))\n",
    "    image = reader.Execute()\n",
    "    img = sitk.GetArrayFromImage(image)\n",
    "    # img = img.transpose((1, 2, 0))\n",
    "    img = img.transpose((2, 1, 0))\n",
    "    all_cands = annotations_df[[\"coordX\", \"coordY\", \"coordZ\", \"diameter_mm\"]][annotations_df[\"seriesuid\"] == name]\n",
    "    all_cands = np.array(all_cands.loc[all_cands.index])\n",
    "    crops = []\n",
    "    if len(all_cands) == 0:\n",
    "        return crops\n",
    "    for (x, y, z, diam) in all_cands:\n",
    "        try:\n",
    "            c = get_class(name, x, y, z)\n",
    "            assert c == 1.0\n",
    "        except AssertionError:\n",
    "            continue\n",
    "        try:\n",
    "            px, py, pz = map(round, xyz2pixels(image, x, y, z))\n",
    "            assert px >= 0 and px < img.shape[0], f\"px = {px}, {img.shape}\"\n",
    "            assert py >= 0 and py < img.shape[1], f\"py = {py}, {img.shape}\"\n",
    "            assert pz >= 0 and pz < img.shape[2], f\"pz = {pz}, {img.shape}\"\n",
    "\n",
    "            xl, xu = max(px - size, 0), min(px + size, img.shape[0])\n",
    "            yl, yu = max(py - size, 0), min(py + size, img.shape[1])\n",
    "            zl, zu = max(pz - size, 0), min(pz + size, img.shape[2])\n",
    "            assert xu - xl == 2 * size and yu - yl == 2 * size and zu - zl == 2 * size\n",
    "            crop = np.copy(img[xl:xu, yl:yu, zl:zu])\n",
    "            crops.append(crop)\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    return crops\n",
    "\n",
    "\n",
    "def crop_negative(name, size=30):\n",
    "    img_path = image_root / (name + \".mhd\")\n",
    "    reader = sitk.ImageFileReader()\n",
    "    reader.SetImageIO(\"MetaImageIO\")\n",
    "    reader.SetFileName(str(img_path))\n",
    "    image = reader.Execute()\n",
    "    img = sitk.GetArrayFromImage(image)\n",
    "    # img = img.transpose((1, 2, 0))\n",
    "    img = img.transpose((2, 1, 0))\n",
    "    all_cands = candidates_df[[\"coordX\", \"coordY\", \"coordZ\", \"class\"]][candidates_df[\"seriesuid\"] == name]\n",
    "    all_cands = np.array(all_cands.loc[all_cands.index])\n",
    "    crops = []\n",
    "    if len(all_cands) == 0:\n",
    "        return crops\n",
    "    for (x, y, z, c) in all_cands:\n",
    "        try:\n",
    "            px, py, pz = map(round, xyz2pixels(image, x, y, z))\n",
    "            assert px >= 0 and px < img.shape[0], f\"px = {px}, {img.shape}\"\n",
    "            assert py >= 0 and py < img.shape[1], f\"py = {py}, {img.shape}\"\n",
    "            assert pz >= 0 and pz < img.shape[2], f\"pz = {pz}, {img.shape}\"\n",
    "\n",
    "            xl, xu = max(px - size, 0), min(px + size, img.shape[0])\n",
    "            yl, yu = max(py - size, 0), min(py + size, img.shape[1])\n",
    "            zl, zu = max(pz - size, 0), min(pz + size, img.shape[2])\n",
    "            assert xu - xl == 2 * size and yu - yl == 2 * size and zu - zl == 2 * size\n",
    "            crop = np.copy(img[xl:xu, yl:yu, zl:zu])\n",
    "            crops.append(crop)\n",
    "            if len(crops) > 3:\n",
    "                return crops\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    return crops\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "sample_nb, size = int(1e3), 30\n",
    "\n",
    "\n",
    "class CropDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(idx, end=\" \")\n",
    "        crops = self.fn(all_samples[idx], size=30)\n",
    "        return crops\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(all_samples)\n",
    "\n",
    "\n",
    "def collate_fn(xs):\n",
    "    return sum(xs, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosDataLoader = DataLoader(CropDataset(crop_positive), num_workers=8, collate_fn=collate_fn, batch_size=8)\n",
    "NegDataLoader = DataLoader(CropDataset(crop_negative), num_workers=8, collate_fn=collate_fn, batch_size=8)\n",
    "\n",
    "# fname = Path(\"\").absolute() / \"data\" / \"positive_crops.bin\"\n",
    "fname = Path(\"~/\").expanduser().absolute() / \"datasets\" / \"positive_crops.bin\"\n",
    "if fname.exists():\n",
    "    all_pos = torch.load(fname)\n",
    "else:\n",
    "    all_pos = sum([crops for crops in PosDataLoader], [])\n",
    "    all_pos = np.stack(all_pos)\n",
    "    amax, amin = np.max(all_pos, (1, 2, 3))[..., None, None, None], np.min(all_pos, (1, 2, 3))[..., None, None, None]\n",
    "    all_pos = (all_pos - amin) / (amax - amin)\n",
    "    torch.save(all_pos.astype(np.float32), fname)\n",
    "\n",
    "# fname = Path(\"\").absolute() / \"data\" / \"negative_crops.bin\"\n",
    "fname = Path(\"~/\").expanduser().absolute() / \"datasets\" / \"negative_crops.bin\"\n",
    "if fname.exists():\n",
    "    all_neg = torch.load(fname)\n",
    "else:\n",
    "    all_neg = sum([crops for crops in NegDataLoader], [])[: len(all_pos)]\n",
    "    all_neg = np.stack(all_neg)\n",
    "    amax, amin = np.max(all_neg, (1, 2, 3))[..., None, None, None], np.min(all_neg, (1, 2, 3))[..., None, None, None]\n",
    "    all_neg = (all_neg - amin) / (amax - amin)\n",
    "    torch.save(all_neg.astype(np.float32), fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize positive and negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17f3774380a43ed8617b547022dc7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=1280.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.figure(4534543)\n",
    "    plt.clf()\n",
    "    r = np.random.randint(0, min(len(all_neg), len(all_pos)))\n",
    "    plt.imshow(all_pos[r][:, :, all_pos[r].shape[2] // 2])\n",
    "    # plt.imshow(all_neg[r][:, :, all_neg[r].shape[2] // 2])\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(Path(\"\") / \"figures\" / f\"positive_crop_{i}.png\", bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure(4534543)\n",
    "    plt.clf()\n",
    "    r = np.random.randint(0, min(len(all_neg), len(all_pos)))\n",
    "    # plt.imshow(all_pos[r][:, :, all_pos[r].shape[2] // 2])\n",
    "    plt.imshow(all_neg[r][:, :, all_neg[r].shape[2] // 2])\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(Path(\"\") / \"figures\" / f\"negative_crop_{i}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crops = np.concatenate([all_pos, all_neg])\n",
    "labels = np.concatenate([np.ones(all_pos.shape[0], dtype=np.int32), np.zeros(all_neg.shape[0], dtype=np.int32)], 0)\n",
    "mask = np.all(np.logical_not(np.isnan(all_crops)), (-1, -2, -3))\n",
    "all_crops, labels = all_crops[mask, ...], labels[mask, ...]\n",
    "STD = torch.std(torch.as_tensor(all_crops, dtype=DTYPE, device=DEVICE), 0)\n",
    "\n",
    "\n",
    "class CroppedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *args, **kw):\n",
    "        super().__init__(*args, **kw)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_3d = torch.as_tensor(all_crops[idx], dtype=torch.float32)  # [None, ...]\n",
    "        return (img_3d, labels[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(labels)\n",
    "\n",
    "\n",
    "def collate_fn(xs):\n",
    "    return torch.utils.data.default_collate([x for x in xs if not torch.any(torch.isnan(x[0]))])\n",
    "\n",
    "\n",
    "train_samples = round(0.8 * len(labels))\n",
    "test_samples = len(labels) - train_samples\n",
    "dataset = CroppedDataset()\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_samples, test_samples])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, num_workers=0, batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_set, num_workers=0, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a731f817ff43d0a25b4d17e0d49f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=59), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 60\n",
    "X_idx = torch.arange(size)[:, None, None].repeat((1, size, size))\n",
    "Y_idx = torch.arange(size)[None, :, None].repeat((size, 1, size))\n",
    "Z_idx = torch.arange(size)[None, None, :].repeat((size, size, 1))\n",
    "MASK = torch.sqrt((X_idx - size // 2) ** 2 + (Y_idx - size // 2) ** 2 + (Z_idx - size // 2) ** 2) <= 10\n",
    "\n",
    "\n",
    "@interact(i=(0, size - 1))\n",
    "def plot(i=0):\n",
    "    plt.figure(54323423)\n",
    "    plt.clf()\n",
    "    plt.imshow(MASK[:, :, i])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00005-62743ad9-fb8b-453d-9b8e-f601cd11e0da",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_height": 264.15625,
    "deepnote_cell_type": "code",
    "id": "5T2XThgosWX-"
   },
   "outputs": [],
   "source": [
    "def generate_model(config):\n",
    "    activation = torch.nn.Softplus(1e1)\n",
    "    model = (\n",
    "        torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(60, 32, 7, 2),\n",
    "            copy(activation),\n",
    "            torch.nn.Conv2d(32, 32, 5, 2),\n",
    "            copy(activation),\n",
    "            torch.nn.Conv2d(32, 32, 3, 1),\n",
    "            copy(activation),\n",
    "            torch.nn.Conv2d(32, 8, 3, 1),\n",
    "            copy(activation),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        .to(DTYPE)\n",
    "        .to(DEVICE)\n",
    "    )\n",
    "    loss_obj = torch.nn.BCELoss()\n",
    "\n",
    "    def loss_fn(Yp, Y, **kw):\n",
    "        kw = dict(config, **kw)\n",
    "        loss = loss_obj(Yp, Y)\n",
    "        loss = loss + sum(config[\"lam\"] * torch.sum(param**2) / 2 for param in model.parameters())\n",
    "        return loss\n",
    "\n",
    "    def cstr_fn(**kw):\n",
    "        kw = dict(config, **kw)\n",
    "        penalty_fn = lambda x: exact_penalty(x, kw.get(\"gam\", None))\n",
    "        #penalty_fn = lambda x: mse_penalty(x, kw.get(\"gam\", None))\n",
    "\n",
    "        if kw.get(\"method\", \"\").lower() == \"lime\":\n",
    "            loss_penalty = LIME_focus(\n",
    "                MASK,\n",
    "                model,\n",
    "                train_loader.dataset,\n",
    "                STD,\n",
    "                penalty_fn=penalty_fn,\n",
    "                test_samples=kw[\"test_samples\"],\n",
    "                bg_samples=kw[\"bg_samples\"],\n",
    "                sample_std=kw[\"sample_std\"],\n",
    "            )\n",
    "        elif kw.get(\"method\", \"\").lower() == \"shap\":\n",
    "            loss_penalty = SHAP_focus(\n",
    "                MASK,\n",
    "                model,\n",
    "                train_loader.dataset,\n",
    "                penalty_fn=penalty_fn,\n",
    "                test_samples=kw[\"test_samples\"],\n",
    "                bg_samples=kw[\"bg_samples\"],\n",
    "            )\n",
    "        else:\n",
    "            loss_penalty = (0, (None for _ in model.parameters()))\n",
    "        return loss_penalty\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.3)\n",
    "    return model, loss_fn, cstr_fn, optimizer, scheduler\n",
    "\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(DTYPE).to(DEVICE), Y.to(DEVICE)\n",
    "            Yp = model(X)\n",
    "            correct += torch.sum((Yp > 0.5).reshape(Y.shape) == Y).detach()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73af5fbf60e409493827070b38e8642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e740735f1e6f43a4b32bcef3f4d77bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main(config):\n",
    "    model, loss_fn, cstr_fn, optimizer, scheduler = generate_model(config)\n",
    "    if config.get(\"method\", \"\") == \"\":\n",
    "        optimizer.param_groups[0][\"lr\"] = 1e-3\n",
    "    shutil.rmtree(Path(\"\") / \"runs\")\n",
    "    writer = SummaryWriter()\n",
    "    rng = tqdm(range(int(150)))\n",
    "    step = -1\n",
    "    hist = dict()\n",
    "    for epoch in rng:\n",
    "        for (i, (X, Y)) in enumerate(train_loader):\n",
    "            step += 1\n",
    "            X, Y = X.to(DTYPE).to(DEVICE, non_blocking=True), Y.to(DTYPE).to(\n",
    "                DEVICE, non_blocking=True\n",
    "            )  # sample a batch\n",
    "            optimizer.zero_grad()  # zero gradients\n",
    "            cstr_val = 0\n",
    "            if epoch > 10:\n",
    "                cstr_val, grads = cstr_fn()\n",
    "                for (grad, param) in zip(grads, model.parameters()):\n",
    "                    if grad is not None:\n",
    "                        param.grad = grad\n",
    "            Yp = model(X).reshape(Y.shape)\n",
    "            loss = loss_fn(Yp, Y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"loss/train\", float(loss), step)\n",
    "            writer.add_scalar(\"step_size\", float(optimizer.param_groups[0][\"lr\"]), step)\n",
    "            writer.add_scalar(\"penalty_metric\", float(cstr_val), step)\n",
    "\n",
    "            hist.setdefault(\"loss_train\", []).append(float(loss))\n",
    "            hist.setdefault(\"penalty_metric\", []).append(float(cstr_val))\n",
    "            writer.flush()\n",
    "        scheduler.step()\n",
    "        train_acc, test_acc = accuracy(model, train_loader), accuracy(model, test_loader)\n",
    "        rng.set_description(f\"Accuracy = (test = {1e2 * test_acc:.3f}%, train = {1e2 * train_acc:.3f}%)\")\n",
    "        writer.add_scalar(\"Accuracy/test\", test_acc, step)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, step)\n",
    "        hist.setdefault(\"acc_test\", []).append(float(test_acc))\n",
    "        hist.setdefault(\"acc_train\", []).append(float(train_acc))\n",
    "    fname = Path(\"~/datasets\").expanduser().absolute() / f\"model_snap_{np.random.randint(0, int(1e9)):d}.bin\"\n",
    "    torch.save((config, hist, model), fname)\n",
    "\n",
    "\n",
    "# config = dict(test_samples=int(1e0), bg_samples=int(1e2), method=\"SHAP\", lam=1e-3, gam=1e0)\n",
    "config = dict(method=\"\", lam=1e-3)\n",
    "main(config)\n",
    "config = dict(test_samples=int(32), bg_samples=int(16), sample_std=1e-2, method=\"LIME\", lam=1e-3, gam=1e2)\n",
    "main(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5139b679d5f84412a1f43e84cc40c48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b68c49c6e04b5991d6e9fcd42d7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = glob.glob(str(Path(\"~\").expanduser() / \"datasets\" / \"model_snap_*.bin\"))\n",
    "acc_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [],\n",
    "        \"Train Accuracy\": [],\n",
    "        \"Test Accuracy\": [],\n",
    "        \"Penalty Value\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "gam, sample_std, bg_samples, test_samples = None, None, None, None\n",
    "\n",
    "for path in paths:\n",
    "    (config, hist, model) = torch.load(path)\n",
    "    gam = gam if \"gam\" not in config else config[\"gam\"]\n",
    "    sample_std = sample_std if \"sample_std\" not in config else config[\"sample_std\"]\n",
    "    bg_samples = bg_samples if \"bg_samples\" not in config else config[\"bg_samples\"]\n",
    "    test_samples = test_samples if \"test_samples\" not in config else config[\"test_samples\"]\n",
    "\n",
    "for path in paths:\n",
    "    (config, hist, model) = torch.load(path)\n",
    "    penalty_vals = []\n",
    "    for i in tqdm(range(20)):\n",
    "        penalty_val, _ = LIME_focus(\n",
    "            MASK,\n",
    "            model,\n",
    "            train_loader.dataset,\n",
    "            STD,\n",
    "            penalty_fn=lambda x: exact_penalty(x, gam),\n",
    "            test_samples=test_samples,\n",
    "            bg_samples=bg_samples,\n",
    "            sample_std=sample_std,\n",
    "        )\n",
    "        penalty_vals.append(float(penalty_val))\n",
    "\n",
    "    penalty_val = np.mean(penalty_vals)\n",
    "    acc_df.loc[len(acc_df)] = [\n",
    "        \"LIME Penalized\" if config.get(\"method\") == \"LIME\" else \"Baseline\",\n",
    "        float(hist[\"acc_train\"][-1]),\n",
    "        float(hist[\"acc_test\"][-1]),\n",
    "        float(penalty_val),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Penalty Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.997503</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.442316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIME Penalized</td>\n",
       "      <td>0.788390</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.346396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Train Accuracy  Test Accuracy  Penalty Value\n",
       "0        Baseline        0.997503         0.7975       0.442316\n",
       "1  LIME Penalized        0.788390         0.7225       0.346396"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(211831)\n",
      "tensor(4169)\n",
      "131817\n",
      "torch.Size([32, 60, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(1 * torch.logical_not(MASK)))\n",
    "print(torch.sum(1 * MASK))\n",
    "print(sum(param.numel() for param in model.parameters()))\n",
    "print(list(model.parameters())[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "          Name &  Train Accuracy &  Test Accuracy &  Penalty Value \\\\\n",
      "\\midrule\n",
      "      Baseline &        0.997503 &         0.7975 &       0.442316 \\\\\n",
      "LIME Penalized &        0.788390 &         0.7225 &       0.346396 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acc_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986\n",
      "1016\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.all(np.logical_not(np.isnan(all_pos)), (-1, -2, -3))))\n",
    "print(np.sum(np.all(np.logical_not(np.isnan(all_neg)), (-1, -2, -3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WIT COMPAS with SHAP",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "f3c3b30d-7a29-47a3-a6e6-89fe2e1d8b52",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
